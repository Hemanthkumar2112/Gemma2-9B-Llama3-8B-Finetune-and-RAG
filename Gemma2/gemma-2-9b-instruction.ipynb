{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install bitsandbytes accelerate\n!pip install -U transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-29T02:21:05.626772Z","iopub.execute_input":"2024-06-29T02:21:05.627121Z","iopub.status.idle":"2024-06-29T02:21:54.403622Z","shell.execute_reply.started":"2024-06-29T02:21:05.627094Z","shell.execute_reply":"2024-06-29T02:21:54.402364Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.30.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.23.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.3.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.43.1\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.41.2)\nCollecting transformers\n  Downloading transformers-4.42.3-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m624.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.2)\nRequirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.3.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nDownloading transformers-4.42.3-py3-none-any.whl (9.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.41.2\n    Uninstalling transformers-4.41.2:\n      Successfully uninstalled transformers-4.41.2\nSuccessfully installed transformers-4.42.3\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Bitsandbytes**: A lightweight CUDA library for quantized matrix multiplication, useful for faster and more memory-efficient computations.\n\n**Accelerate**: A library by Hugging Face to accelerate training and inference on multiple devices, including CPUs, GPUs, and TPUs.","metadata":{}},{"cell_type":"markdown","source":"**Device Mapping for Model Layers**\nWhen dealing with large models, distributing the layers across multiple devices can help in managing memory and computational resources more efficiently. The device_maps variable is used to specify which layers of the model are assigned to which device.","metadata":{}},{"cell_type":"code","source":"device_maps = [('model.layers.0', 0),\n ('model.layers.1', 0),\n ('model.layers.2', 0),\n ('model.layers.3', 0),\n ('model.layers.4', 0),\n ('model.layers.5', 0),\n ('model.layers.6', 0),\n ('model.layers.7', 0),\n ('model.layers.8', 0),\n ('model.layers.9', 0),\n ('model.layers.10', 0),\n ('model.layers.11', 0),\n ('model.layers.12', 0),\n ('model.layers.13', 0),\n ('model.layers.14', 0),\n ('model.layers.15', 0),\n ('model.layers.16', 0),\n ('model.layers.17', 0),\n ('model.layers.18', 0),\n ('model.layers.19', 1),\n ('model.layers.20', 1),\n ('model.layers.21', 1),\n ('model.layers.22', 1),\n ('model.layers.23', 1),\n ('model.layers.24', 1),\n ('model.layers.25', 1),\n ('model.layers.26', 1),\n ('model.layers.27', 1),\n ('model.layers.28', 1),\n ('model.layers.29', 1),\n ('model.layers.30', 1),\n ('model.layers.31', 1),\n ('model.layers.32', 1),\n ('model.layers.33', 1),\n ('model.layers.34', 1),\n ('model.layers.35', 1),\n ('model.layers.36', 1),\n ('model.layers.37', 1),\n ('model.layers.38', 1),\n ('model.layers.39', 1),\n ('model.layers.40', 1),\n ('model.layers.41', 1),\n ('model.embed_tokens', 1),\n ('model.layers', 1)]","metadata":{"execution":{"iopub.status.busy":"2024-06-29T02:21:54.406519Z","iopub.execute_input":"2024-06-29T02:21:54.407389Z","iopub.status.idle":"2024-06-29T02:21:54.417171Z","shell.execute_reply.started":"2024-06-29T02:21:54.407347Z","shell.execute_reply":"2024-06-29T02:21:54.416215Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"hf_token\")","metadata":{"execution":{"iopub.status.busy":"2024-06-29T02:22:46.468111Z","iopub.execute_input":"2024-06-29T02:22:46.468477Z","iopub.status.idle":"2024-06-29T02:22:46.603615Z","shell.execute_reply.started":"2024-06-29T02:22:46.468446Z","shell.execute_reply":"2024-06-29T02:22:46.602879Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import torch\ntorch.backends.cuda.enable_mem_efficient_sdp(False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"By using torch.backends.cuda.enable_mem_efficient_sdp(False), you can disable memory-efficient SDP in PyTorch, which might be necessary for certain models or debugging purposes. This configuration can help achieve better performance or consistency across different hardware setups.","metadata":{}},{"cell_type":"code","source":"from transformers import (AutoTokenizer, AutoModelForCausalLM, \n                          BitsAndBytesConfig, AutoConfig)\n\nquantization_config = BitsAndBytesConfig(load_in_8bit=True)\nmodel_name = \"google/gemma-2-9b-it\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name,\n                                          token =secret_value_0) \n","metadata":{"execution":{"iopub.status.busy":"2024-06-29T02:21:54.568174Z","iopub.execute_input":"2024-06-29T02:21:54.568466Z","iopub.status.idle":"2024-06-29T02:22:03.011214Z","shell.execute_reply.started":"2024-06-29T02:21:54.568440Z","shell.execute_reply":"2024-06-29T02:22:03.009927Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/40.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98736051f79b4bb998bb845cd8c18a8c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49bc45a5b70647858dc2a322b80afde9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bea86d442dd0400dbce2db6eb6345b20"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cab17715a4e4b3da20d2f74e4e499a7"}},"metadata":{}}]},{"cell_type":"code","source":"device= {layer:gpu_mem for (layer,gpu_mem) in device_maps}","metadata":{"execution":{"iopub.status.busy":"2024-06-29T02:22:03.012741Z","iopub.execute_input":"2024-06-29T02:22:03.013259Z","iopub.status.idle":"2024-06-29T02:22:03.021224Z","shell.execute_reply.started":"2024-06-29T02:22:03.013221Z","shell.execute_reply":"2024-06-29T02:22:03.019962Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":" \nconfig = AutoConfig.from_pretrained(model_name,token=secret_value_0)\nconfig.gradient_checkpointing = True","metadata":{"execution":{"iopub.status.busy":"2024-06-29T02:23:08.348759Z","iopub.execute_input":"2024-06-29T02:23:08.349641Z","iopub.status.idle":"2024-06-29T02:23:08.508835Z","shell.execute_reply.started":"2024-06-29T02:23:08.349607Z","shell.execute_reply":"2024-06-29T02:23:08.507889Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/857 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3860ecd2d5a4c4c9a93171f5bfdffd4"}},"metadata":{}}]},{"cell_type":"code","source":"config","metadata":{"execution":{"iopub.status.busy":"2024-06-29T02:23:13.934363Z","iopub.execute_input":"2024-06-29T02:23:13.935077Z","iopub.status.idle":"2024-06-29T02:23:13.942412Z","shell.execute_reply.started":"2024-06-29T02:23:13.935043Z","shell.execute_reply":"2024-06-29T02:23:13.941216Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Gemma2Config {\n  \"_name_or_path\": \"google/gemma-2-9b-it\",\n  \"architectures\": [\n    \"Gemma2ForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"attn_logit_softcapping\": 50.0,\n  \"bos_token_id\": 2,\n  \"cache_implementation\": \"hybrid\",\n  \"eos_token_id\": 1,\n  \"final_logit_softcapping\": 30.0,\n  \"gradient_checkpointing\": true,\n  \"head_dim\": 256,\n  \"hidden_act\": \"gelu_pytorch_tanh\",\n  \"hidden_activation\": \"gelu_pytorch_tanh\",\n  \"hidden_size\": 3584,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 14336,\n  \"max_position_embeddings\": 8192,\n  \"model_type\": \"gemma2\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 42,\n  \"num_key_value_heads\": 8,\n  \"pad_token_id\": 0,\n  \"query_pre_attn_scalar\": 224,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_theta\": 10000.0,\n  \"sliding_window\": 4096,\n  \"sliding_window_size\": 4096,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.42.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 256000\n}"},"metadata":{}}]},{"cell_type":"code","source":"\nmodel = AutoModelForCausalLM.from_pretrained(model_name ,torch_dtype=\"auto\",quantization_config=quantization_config,token =secret_value_0,\n                                             device_map=\"auto\",trust_remote_code=True,config=config)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T02:23:20.219850Z","iopub.execute_input":"2024-06-29T02:23:20.220271Z","iopub.status.idle":"2024-06-29T02:26:38.359528Z","shell.execute_reply.started":"2024-06-29T02:23:20.220238Z","shell.execute_reply":"2024-06-29T02:26:38.358748Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/39.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"975d8a6fa6e74c7c870ba77dfbf0efb3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73b4be7587db40d9af7cbfe73491161c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2538c33562c415a98e441b2c14c8937"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"609f158f45f2479a9c02e363bf58d025"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"636edc6b60cf48eb8fd0419845d7cfb8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/3.67G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59a419425f1e45fbaeff25ebb4721623"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6355d12664f4eb3904ac2473a641490"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/173 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b0421fc4eb049d58abbade199ba3bfd"}},"metadata":{}}]},{"cell_type":"code","source":"input_text = \"correct this sentense: He does eat meat everyday\"\ninput_ids = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n\noutputs = model.generate(**input_ids,max_length=150)\nprint(tokenizer.decode(outputs[0]))","metadata":{"execution":{"iopub.status.busy":"2024-06-29T02:28:18.051733Z","iopub.execute_input":"2024-06-29T02:28:18.052130Z","iopub.status.idle":"2024-06-29T02:29:32.028702Z","shell.execute_reply.started":"2024-06-29T02:28:18.052098Z","shell.execute_reply":"2024-06-29T02:29:32.027718Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"2024-06-29 02:28:22.551394: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-29 02:28:22.551496: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-29 02:28:22.825696: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","output_type":"stream"},{"name":"stdout","text":"<bos>correct this sentense: He does eat meat everyday.\n\nThe corrected sentence is: **He eats meat every day.**\n\n\nHere's why:\n\n* **Subject-Verb Agreement:**  \"He\" is singular, so the verb needs to be \"eats\" (singular present tense) instead of \"does eat\" (present tense with auxiliary verb).\n* **Word Order:**  In English, the typical word order for this type of sentence is subject-verb-adverbial.  \"Every day\" is an adverbial phrase modifying \"eats\". \n\n\n\nLet me know if you have any other sentences you'd like help with!<end_of_turn>\n<eos>\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}